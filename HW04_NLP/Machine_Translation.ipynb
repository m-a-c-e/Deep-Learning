{"cells":[{"cell_type":"markdown","metadata":{"id":"p3-VNVJP7dlG"},"source":["# CS 4464/7643 Deep Learning HW 4\n","### Machine Translation with Seq2Seq and Transformers\n","In this exercise you will implement a [Sequence to Sequence(Seq2Seq)](https://arxiv.org/abs/1703.03906) and a [Transformer](https://arxiv.org/pdf/1706.03762.pdf) model and use them to perform machine translation.\n","\n","**A quick note: if you receive the following TypeError \"super(type, obj): obj must be an instance or subtype of type\", try re-importing that part or restarting your kernel and re-running all cells.** Once you have finished making changes to the model constuctor, you can avoid this issue by commenting out all of the model instantiations after the first (e.g. lines starting with \"model = TransformerTranslator(*args, **kwargs)\")."],"id":"p3-VNVJP7dlG"},{"cell_type":"markdown","metadata":{"id":"oXtSSACyMN5T"},"source":["#### Google Colab Setup\n","Edit and run the cell below to setup the environment for Google Colab (and only for Google Colab)."],"id":"oXtSSACyMN5T"},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":125690,"status":"ok","timestamp":1668117479187,"user":{"displayName":"Deep Learning (Deep Learning)","userId":"05582513555958405370"},"user_tz":300},"id":"hBD1zdSe0OuY","outputId":"e41b0ffd-94fc-47dc-fac8-a205e11ad5c3","scrolled":true},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/hw4_student_version\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting torchtext==0.9\n","  Downloading torchtext-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (7.1 MB)\n","\u001b[K     |████████████████████████████████| 7.1 MB 4.4 MB/s \n","\u001b[?25hCollecting torch==1.8.0\n","  Downloading torch-1.8.0-cp37-cp37m-manylinux1_x86_64.whl (735.5 MB)\n","\u001b[K     |████████████████████████████████| 735.5 MB 14 kB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.9) (1.21.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.9) (2.23.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.9) (4.64.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0->torchtext==0.9) (4.1.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9) (2022.9.24)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9) (2.10)\n","Installing collected packages: torch, torchtext\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.12.1+cu113\n","    Uninstalling torch-1.12.1+cu113:\n","      Successfully uninstalled torch-1.12.1+cu113\n","  Attempting uninstall: torchtext\n","    Found existing installation: torchtext 0.13.1\n","    Uninstalling torchtext-0.13.1:\n","      Successfully uninstalled torchtext-0.13.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchvision 0.13.1+cu113 requires torch==1.12.1, but you have torch 1.8.0 which is incompatible.\n","torchaudio 0.12.1+cu113 requires torch==1.12.1, but you have torch 1.8.0 which is incompatible.\u001b[0m\n","Successfully installed torch-1.8.0 torchtext-0.9.0\n"]}],"source":["# Cell 1\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Change this path to the correct one for you\n","%cd /content/drive/MyDrive/hw4_student_version/\n","\n","%pip install torchtext==0.9"],"id":"hBD1zdSe0OuY"},{"cell_type":"markdown","metadata":{"id":"pku3xeT37phM"},"source":["### Introduction\n","\n","#### Multi30K: Multilingual English-German Image Descriptions\n","\n","[Multi30K](https://github.com/multi30k/dataset) is a dataset for machine translation tasks. It is a multilingual corpus containing English sentences and their German translation. In total it contains 31014 sentences(29000 for training, 1014 for validation, and 1000 for testing).\n","As one example:\n","\n","En: `Two young, White males are outside near many bushes.`\n","\n","De: `Zwei junge weiße Männer sind im Freien in der Nähe vieler Büsche.`\n","\n","You can read more info about the dataset [here](https://arxiv.org/abs/1605.00459). The following parts of this assignment will be based on this dataset.\n","\n","#### TorchText: A PyTorch Toolkit for Text Dataset and NLP Tasks\n","[TorchText](https://github.com/pytorch/text) is a PyTorch package that consists of data processing utilities and popular datasets for natural language. The key idea of TorchText is that datasets can be organized in *Field*, *TralsationDataset*, and *BucketIterator* classes. They serve to help with data splitting and loading, token encoding, sequence padding, etc. You don't need to know about how TorchText works in detail, but you might want to know about why those classes are needed and what operations are necessary for machine translation. This knowledge can be migrated to all sequential data modeling. In the following parts, we will provide you with some code to help you understand.\n","\n"," You can refer to torchtext's documentation(v0.6.0) [here](https://pytorch.org/text/).\n","\n","#### Spacy\n","Spacy is package designed for tokenization in many languages. Tokenization is a process of splitting raw text data into lists of tokens that can be further processed. Since TorchText only provides tokenizer for English, we will be using Spacy for our assignment. "],"id":"pku3xeT37phM"},{"cell_type":"markdown","metadata":{"id":"6M9cim2EBI2m"},"source":["### Prerequisites\n","Before you start this assignment, please make sure you have the following package installed:\n","\n","`PyTorch, TorchText, Spacy, Tqdm, Numpy`\n","\n","You can first check using either `pip freeze` in terminal or `conda list` in conda environment. Then run the following code blocks to make sure they can be imported."],"id":"6M9cim2EBI2m"},{"cell_type":"code","execution_count":2,"metadata":{"id":"knET94spBbsX","executionInfo":{"status":"ok","timestamp":1668117866963,"user_tz":300,"elapsed":947,"user":{"displayName":"Deep Learning (Deep Learning)","userId":"05582513555958405370"}}},"outputs":[],"source":["# Cell 4\n","import numpy as np\n","import csv\n","import torch\n","\n","# for auto-reloading external modules\n","# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n","%load_ext autoreload\n","%autoreload 2"],"id":"knET94spBbsX"},{"cell_type":"code","execution_count":3,"metadata":{"id":"t0TWNG28QEXf","executionInfo":{"status":"ok","timestamp":1668117868592,"user_tz":300,"elapsed":532,"user":{"displayName":"Deep Learning (Deep Learning)","userId":"05582513555958405370"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"6496d555-2adf-4a20-b9ef-4470e26366ce"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/hw4_student_version\n"]}],"source":["%cd /content/drive/MyDrive/hw4_student_version/\n","\n","# Cell 5\n","# Just run this block. Please do not modify the following code.\n","import math\n","import time\n","\n","# Pytorch package\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","# Torchtext package\n","from torchtext.legacy.datasets\timport Multi30k\n","from torchtext.legacy.data import Field, BucketIterator\n","\n","# Tqdm progress bar\n","from tqdm import tqdm_notebook\n","\n","# Code provided to you for training and evaluation\n","from utils import train, evaluate, set_seed_nb, unit_test_values"],"id":"t0TWNG28QEXf"},{"cell_type":"markdown","metadata":{"id":"hFKXhBodH4sm"},"source":["Once you properly import the above packages, you can proceed to download Spacy English and German tokenizers by running the following commands in your **terminal** (if working locally). Otherwise, run the following cell on Google Colab. They will take some time."],"id":"hFKXhBodH4sm"},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26968,"status":"ok","timestamp":1668117902119,"user":{"displayName":"Deep Learning (Deep Learning)","userId":"05582513555958405370"},"user_tz":300},"id":"Yf2Tj2YQIH_9","outputId":"9d9dcac3-06cf-4f90-fd06-94e8bb9975c3"},"outputs":[{"output_type":"stream","name":"stdout","text":["2022-11-10 22:04:42.223335: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n","\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'en' are deprecated. Please use the\n","full pipeline package name 'en_core_web_sm' instead.\u001b[0m\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting en-core-web-sm==3.4.1\n","  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.4.1/en_core_web_sm-3.4.1-py3-none-any.whl (12.8 MB)\n","\u001b[K     |████████████████████████████████| 12.8 MB 5.3 MB/s \n","\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from en-core-web-sm==3.4.1) (3.4.2)\n","Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (8.1.5)\n","Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.4.2)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.0.7)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.23.0)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (4.64.1)\n","Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.10.1)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.21.6)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.10.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.11.3)\n","Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (4.1.1)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.0.10)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.0.9)\n","Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.6.2)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.0.8)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.0.3)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.4.5)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.3.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (57.4.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (21.3)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.0.8)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.10.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.0.9)\n","Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (5.2.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2022.9.24)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.0.4)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.0.3)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.7.9)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (7.1.2)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.0.1)\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('en_core_web_sm')\n","2022-11-10 22:04:54.493460: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n","\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'de' are deprecated. Please use the\n","full pipeline package name 'de_core_news_sm' instead.\u001b[0m\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting de-core-news-sm==3.4.0\n","  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.4.0/de_core_news_sm-3.4.0-py3-none-any.whl (14.6 MB)\n","\u001b[K     |████████████████████████████████| 14.6 MB 3.2 MB/s \n","\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from de-core-news-sm==3.4.0) (3.4.2)\n","Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (8.1.5)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.4.5)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (4.64.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (57.4.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.11.3)\n","Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (0.4.2)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (1.0.9)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (1.10.2)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (3.0.8)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.0.8)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.0.7)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (1.21.6)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (3.3.0)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.23.0)\n","Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (4.1.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (21.3)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (1.0.3)\n","Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (0.10.1)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (3.0.10)\n","Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (0.6.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (3.10.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (3.0.9)\n","Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (5.2.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2022.9.24)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (3.0.4)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (0.0.3)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (0.7.9)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (7.1.2)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.0.1)\n","Installing collected packages: de-core-news-sm\n","Successfully installed de-core-news-sm-3.4.0\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('de_core_news_sm')\n"]}],"source":["# Cell 6\n","!python -m spacy download en\n","!python -m spacy download de"],"id":"Yf2Tj2YQIH_9"},{"cell_type":"markdown","metadata":{"id":"f5B91bBSImQe"},"source":["Check your GPU availability and load some sanity checkers"],"id":"f5B91bBSImQe"},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":128,"status":"ok","timestamp":1668117950845,"user":{"displayName":"Deep Learning (Deep Learning)","userId":"05582513555958405370"},"user_tz":300},"id":"RNZZrUYmIn8Y","outputId":"11175072-5ea9-433b-c5bd-8260856ba532"},"outputs":[{"output_type":"stream","name":"stdout","text":["False\n","You are using device: cpu\n"]}],"source":["# Cell 7\n","# Check device availability\n","\n","print(torch.cuda.is_available())\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(\"You are using device: %s\" % device)"],"id":"RNZZrUYmIn8Y"},{"cell_type":"markdown","metadata":{"id":"_VKvvadEIzK8"},"source":["#### Preprocess data\n","\n","With TorchText and Spacy tokenizers ready, you can now prepare the data using TorchText objects. Just run the following code blocks. Read the comment and try to understand what they are for."],"id":"_VKvvadEIzK8"},{"cell_type":"code","execution_count":6,"metadata":{"id":"g7XkX5t_IvGl","executionInfo":{"status":"ok","timestamp":1668117952733,"user_tz":300,"elapsed":833,"user":{"displayName":"Deep Learning (Deep Learning)","userId":"05582513555958405370"}}},"outputs":[],"source":["# Cell 8\n","# load checkers\n","d1 = torch.load('./data/d1.pt') \n","d2 = torch.load('./data/d2.pt')\n","d3 = torch.load('./data/d3.pt')\n","d4 = torch.load('./data/d4.pt')"],"id":"g7XkX5t_IvGl"},{"cell_type":"code","execution_count":7,"metadata":{"id":"SiRXFN_fI5Pm","executionInfo":{"status":"ok","timestamp":1668117969190,"user_tz":300,"elapsed":16001,"user":{"displayName":"Deep Learning (Deep Learning)","userId":"05582513555958405370"}}},"outputs":[],"source":["# Cell 9\n","# You don't need to modify any code in this block\n","\n","# Define the maximum length of the sentence. Shorter sentences will be padded to that length and longer sentences will be croped. Given that the average length of the sentence in the corpus is around 13, we can set it to 20\n","MAX_LEN = 20\n","\n","# Define the source and target language\n","SRC = Field(tokenize = \"spacy\",\n","            tokenizer_language=\"de_core_news_sm\",\n","            init_token = '<sos>',\n","            eos_token = '<eos>',\n","            fix_length = MAX_LEN,\n","            lower = True)\n","\n","TRG = Field(tokenize = \"spacy\",\n","            tokenizer_language=\"en_core_web_sm\",\n","            init_token = '<sos>',\n","            eos_token = '<eos>',\n","            fix_length = MAX_LEN,\n","            lower = True)\n","\n","# Download and split the data. It should take some time\n","train_data, valid_data, test_data = Multi30k.splits(exts = ('.de', '.en'),\n","                                                    fields = (SRC, TRG))"],"id":"SiRXFN_fI5Pm"},{"cell_type":"code","execution_count":8,"metadata":{"id":"6Fs_ZqfbI5D3","executionInfo":{"status":"ok","timestamp":1668117974680,"user_tz":300,"elapsed":527,"user":{"displayName":"Deep Learning (Deep Learning)","userId":"05582513555958405370"}}},"outputs":[],"source":["# Cell 10\n","# Define Batchsize\n","BATCH_SIZE = 128\n","\n","# Build the vocabulary associated with each language\n","SRC.build_vocab(train_data, min_freq = 2)\n","TRG.build_vocab(train_data, min_freq = 2)\n","\n","# Get the padding index to be ignored later in loss calculation\n","PAD_IDX = TRG.vocab.stoi['<pad>']\n","\n","# Get data-loaders using BucketIterator\n","train_loader, valid_loader, test_loader = BucketIterator.splits(\n","    (train_data, valid_data, test_data),\n","    batch_size = BATCH_SIZE, device = device)\n","\n","# Get the input and the output sizes for model\n","input_size = len(SRC.vocab)\n","output_size = len(TRG.vocab)"],"id":"6Fs_ZqfbI5D3"},{"cell_type":"markdown","metadata":{"id":"NMJSBzha56Cm"},"source":["### Part 1: RNNs and LSTMs\n","\n","In this section, you will need to implement a Vanilla RNN and an LSTM unit using PyTorch Linear layers and nn.Parameter. This is designed to help you to understand how they work behind the scene. The code you will be working with is in *LSTM.py* and *RNN.py* under *naive* folder. Please refer to instructions among this notebook and those files. "],"id":"NMJSBzha56Cm"},{"cell_type":"markdown","metadata":{"id":"jG5O2sm-CaZ_"},"source":["#### 1.1 Implement an RNN Unit\n","\n","In this section you will be using PyTorch Linear layers and activations to implement a vanilla RNN unit. Run the following block to check your implementation."],"id":"jG5O2sm-CaZ_"},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":792,"status":"ok","timestamp":1668117978018,"user":{"displayName":"Deep Learning (Deep Learning)","userId":"05582513555958405370"},"user_tz":300},"id":"HLp78q5P19ed","outputId":"4361e65e-1665-491f-b4cc-5481125e89d5"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([5, 3])\n","torch.Size([5, 4])\n","tensor([[-0.9717,  0.9257, -0.9781,  0.9998],\n","        [-0.8943,  0.9526, -0.9394,  0.9994],\n","        [-0.6433,  0.9699, -0.8381,  0.9977],\n","        [-0.0845,  0.9810, -0.6024,  0.9915],\n","        [ 0.5330,  0.9880, -0.1771,  0.9690]], grad_fn=<SliceBackward>)\n","Close to out:  True\n","Close to hidden:  True\n"]}],"source":["# Cell 11\n","from models.naive.RNN import VanillaRNN\n","\n","set_seed_nb()\n","x1,x2 = (1,4), (-1,2)\n","h1,h2 = (-1,2,0,4), (0,1,3,-1)\n","batch = 5\n","x = torch.FloatTensor(np.linspace(x1,x2,batch))\n","h = torch.FloatTensor(np.linspace(h1,h2,batch))\n","\n","rnn = VanillaRNN(x.shape[-1], h.shape[-1], 3)\n","out, hidden = rnn.forward(x,h)\n","print(out.size())\n","print(hidden.size())\n","print(hidden)\n","expected_out, expected_hidden = unit_test_values('rnn')\n","\n","if out is not None:\n","    print('Close to out: ', expected_out.allclose(out, atol=1e-4))\n","    print('Close to hidden: ', expected_hidden.allclose(hidden, atol=1e-4))\n","else:\n","    print(\"NOT IMPLEMENTED\")"],"id":"HLp78q5P19ed"},{"cell_type":"markdown","metadata":{"id":"N3rsFEHhDIKD"},"source":["#### 1.2 Implement an LSTM Unit\n","\n","In this section you will be using PyTorch nn.Parameter and activations to implement an LSTM unit. You can simply translate the following equations using nn.Parameter and PyTorch activation functions to build an LSTM from scratch: \n","\\begin{array}{ll} \\\\\n","    i_t = \\sigma(W_{ii} x_t + b_{ii} + W_{hi} h_{t-1} + b_{hi}) \\\\\n","    f_t = \\sigma(W_{if} x_t + b_{if} + W_{hf} h_{t-1} + b_{hf}) \\\\\n","    g_t = \\tanh(W_{ig} x_t + b_{ig} + W_{hg} h_{t-1} + b_{hg}) \\\\\n","    o_t = \\sigma(W_{io} x_t + b_{io} + W_{ho} h_{t-1} + b_{ho}) \\\\\n","    c_t = f_t \\odot c_{t-1} + i_t \\odot g_t \\\\\n","    h_t = o_t \\odot \\tanh(c_t) \\\\\n","\\end{array}\n","\n","Here's a great visualization of the above equation from [Colah's blog](https://colah.github.io/posts/2015-08-Understanding-LSTMs/) to help you understand LSTM unit. You can also read more about it from that blog.\n","\n","If you want to see nn.Parameter in example, check out this [tutorial](https://pytorch.org/tutorials/beginner/nn_tutorial.html) from PyTorch. Run the following block to check your implementation"],"id":"N3rsFEHhDIKD"},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MzsgDA5uFAXO","executionInfo":{"status":"ok","timestamp":1668117982790,"user_tz":300,"elapsed":397,"user":{"displayName":"Deep Learning (Deep Learning)","userId":"05582513555958405370"}},"outputId":"5acc5f19-4bf1-43a0-e70e-788bacd21c41"},"outputs":[{"output_type":"stream","name":"stdout","text":["Close to h_t:  True\n","Close to c_t:  True\n"]}],"source":["# Cell 12\n","from models.naive.LSTM import LSTM\n","\n","set_seed_nb()\n","x1,x2 = np.mgrid[-1:3:3j, -1:4:2j]\n","h1,h2 = np.mgrid[-2:2:3j, 1:3:4j]\n","batch = 4\n","x = torch.FloatTensor(np.linspace(x1,x2,batch))\n","h = torch.FloatTensor(np.linspace(h1,h2,batch))\n","\n","lstm = LSTM(x.shape[-1], h.shape[-1])\n","h_t, c_t = lstm.forward(x)\n","\n","expected_ht, expected_ct = unit_test_values('lstm')\n","\n","print('Close to h_t: ', expected_ht.allclose(h_t, atol=1e-3))\n","print('Close to c_t: ', expected_ct.allclose(c_t, atol=1e-3))"],"id":"MzsgDA5uFAXO"},{"cell_type":"markdown","metadata":{"id":"wVhDvoR9F4S6"},"source":["### Part 2: Train a Seq2Seq Model\n","In this section, you will be working on implementing a simple Seq2Seq model. You will first implement an Encoder and a Decoder, and then join them together with a Seq2Seq architecture. You will need to complete the code in *Decoder.py*, *Encoder.py*, and *Seq2Seq.py* under *seq2seq* folder. Please refer to the instructions in those files."],"id":"wVhDvoR9F4S6"},{"cell_type":"markdown","metadata":{"id":"F8vwg8IGGyMG"},"source":["#### Implement the Encoder\n","\n","In this section you will be implementing an RNN/LSTM based encoder to model English texts. Please refer to the instructions in *seq2seq/Encoder.py*. Run the following block to check your implementation. "],"id":"F8vwg8IGGyMG"},{"cell_type":"code","execution_count":null,"metadata":{"id":"powIPS2yGfkQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1667943229526,"user_tz":300,"elapsed":110,"user":{"displayName":"Deep Learning (Deep Learning)","userId":"05582513555958405370"}},"outputId":"e1f547eb-0b0f-495f-8caa-11c62c8a985e"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([1, 5, 2])\n","torch.Size([5, 1, 2])\n","Close to out:  True\n","Close to hidden:  True\n"]}],"source":["# Cell 13\n","from models.seq2seq.Encoder import Encoder as Encoder\n","import pdb\n","\n","set_seed_nb()\n","i, n, h = 10, 4, 2\n","\n","encoder = Encoder(i, n, h, h)\n","x_array = np.random.rand(5,1) * 10\n","x = torch.LongTensor(x_array)\n","out, hidden = encoder.forward(x)\n","print(hidden.size())\n","print(out.size())\n","\n","expected_out, expected_hidden = unit_test_values('encoder')\n","print('Close to out: ', expected_out.allclose(out, atol=1e-4))\n","print('Close to hidden: ', expected_hidden.allclose(hidden, atol=1e-4))"],"id":"powIPS2yGfkQ"},{"cell_type":"markdown","metadata":{"id":"Aq2vkg4uG6ww"},"source":["#### Implement the Decoder\n","\n","In this section you will be implementing an RNN/LSTM based decoder to model German texts. Please refer to the instructions in *seq2seq/Decoder.py*. Run the following block to check your implementation. "],"id":"Aq2vkg4uG6ww"},{"cell_type":"code","execution_count":null,"metadata":{"id":"Fsoz-My2GfZg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1667847194465,"user_tz":300,"elapsed":839,"user":{"displayName":"Deep Learning (Deep Learning)","userId":"05582513555958405370"}},"outputId":"1f145f85-2984-4596-ef7d-b4549edc8489"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([1, 5, 2])\n","torch.Size([1, 5, 2])\n","torch.Size([5, 10])\n","torch.Size([5, 10])\n","Close to out:  True\n","Close to hidden:  True\n"]}],"source":["# Cell 14\n","from models.seq2seq.Decoder import Decoder as Decoder\n","import pdb\n","\n","set_seed_nb()\n","i, n, h =  10, 2, 2\n","\n","decoder = Decoder(h, n, n, i)\n","x_array = np.random.rand(5, 1) * 10\n","x = torch.LongTensor(x_array)\n","_, enc_hidden = unit_test_values('encoder')\n","out, hidden = decoder.forward(x,enc_hidden)\n","\n","expected_out, expected_hidden = unit_test_values('decoder')\n","print(hidden.size())\n","print(expected_hidden.size())\n","print(out.size())\n","print(expected_out.size())\n","print('Close to out: ', expected_out.allclose(out, atol=1e-4))\n","print('Close to hidden: ', expected_hidden.allclose(hidden, atol=1e-4))\n"],"id":"Fsoz-My2GfZg"},{"cell_type":"markdown","metadata":{"id":"4d6aiNn7G9c8"},"source":["#### Implement the Seq2Seq\n","\n","In this section you will be implementing the Seq2Seq model that utilizes the Encoder and Decoder you implemented. Please refer to the instructions in *seq2seq/Seq2Seq.py*. Run the following block to check your implementation."],"id":"4d6aiNn7G9c8"},{"cell_type":"code","execution_count":null,"metadata":{"id":"81ya7FY4GfJf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1667945130267,"user_tz":300,"elapsed":551,"user":{"displayName":"Deep Learning (Deep Learning)","userId":"05582513555958405370"}},"outputId":"13735dc2-5c81-4d59-fa54-8b07e17c3409"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([1, 2, 8])\n","tensor([[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n","           0.0000],\n","         [-2.4136, -2.2861, -1.7145, -2.5612, -1.9864, -2.0557, -1.7461,\n","          -2.1898]]])\n","Close to out:  True\n"]}],"source":["\n","# Cell 15\n","import pdb\n","\n","from models.seq2seq.Seq2Seq import Seq2Seq\n","from models.seq2seq.Decoder import Decoder\n","from models.seq2seq.Encoder import Encoder\n","set_seed_nb()\n","embedding_size = 32\n","hidden_size = 32\n","input_size = 8\n","output_size = 8\n","batch, seq = 1, 2\n","\n","encoder = Encoder(input_size, embedding_size, hidden_size, hidden_size)\n","decoder = Decoder(embedding_size, hidden_size, hidden_size, output_size)\n","\n","seq2seq = Seq2Seq(encoder, decoder, 'cpu')\n","x_array = np.random.rand(batch, seq) * 10\n","x = torch.LongTensor(x_array)\n","\n","out = seq2seq.forward(x)\n","expected_out = unit_test_values('seq2seq')\n","print(out.size())\n","print(expected_out)\n","print('Close to out: ', expected_out.allclose(out, atol=1e-4))"],"id":"81ya7FY4GfJf"},{"cell_type":"markdown","metadata":{"id":"DysC2LtLHKyu"},"source":["#### Train your Seq2Seq model\n","\n","Now its time to combine what we have and train a Seq2Seq translator. We provided you with some training code and you can simply run them to see how your translator works. If you implemented everything correctly, you should see some meaningful translation in the output. You can modify the hyperparameters to improve the results. You can also tune the BATCH_SIZE in section Preprocess data."],"id":"DysC2LtLHKyu"},{"cell_type":"code","execution_count":null,"metadata":{"id":"gfvSwMUaHWi1"},"outputs":[],"source":["# Cell 16\n","# Hyperparameters. You are welcome to modify these\n","encoder_emb_size = 64\n","encoder_hidden_size = 64\n","encoder_dropout = 0.1\n","\n","decoder_emb_size = 64\n","decoder_hidden_size = 64\n","decoder_dropout = 0.1\n","\n","learning_rate = 5e-3\n","model_type = \"RNN\"\n","\n","EPOCHS = 5\n","\n","#input size and output size\n","input_size = len(SRC.vocab)\n","output_size = len(TRG.vocab)"],"id":"gfvSwMUaHWi1"},{"cell_type":"code","execution_count":null,"metadata":{"id":"8xJk1LKtKAIp"},"outputs":[],"source":["# Cell 17\n","# Declare models, optimizer, and loss function\n","encoder = Encoder(input_size, encoder_emb_size, encoder_hidden_size, decoder_hidden_size, dropout = encoder_dropout, model_type = model_type)\n","decoder = Decoder(decoder_emb_size, encoder_hidden_size, encoder_hidden_size, output_size, dropout = decoder_dropout, model_type = model_type)\n","seq2seq_model = Seq2Seq(encoder, decoder, device)\n","\n","optimizer = optim.Adam(seq2seq_model.parameters(), lr = learning_rate)\n","criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)"],"id":"8xJk1LKtKAIp"},{"cell_type":"code","execution_count":null,"metadata":{"id":"OWFIwNJrKDWJ","colab":{"base_uri":"https://localhost:8080/","height":966,"referenced_widgets":["e3468ca6c468413d8348da01a3a6d6c0","8ce1395edf434a37b3c6496b2b1ec638","279a33ace54e4eeca3f944e56efbae41","3abd786ef55547cbb47ded55d1679972","d52c36ee63d44e5fafd2326a571a0b0d","9f9c06d838ce4a1d973c4c6faf863ecf","a9d9c083e54d4ea697c4f00e6238dbaa","d6cd62dc037f4a9aa3240b7432865845","5e3d3a287edc49a588ad51a0513c14f1","cf7a78180db44605be2bb0feaeee0a7d","703695b62db5469eb7c64dc4d7dc4419","add8b565459f4cfa9d85e40f74e3170c","9e21e636599b42dcbf4512dc94e8ed83","e83267fc131b4537880e261443bcc962","0a54c0c4483b47498b008533819bcec5","ddf9ba0fa84e425ba4ce75ddaeedf3d5","03eedd1394504ef9b6bfb075e18d3fc0","c2be8a89d4a34cdbb1e2658506848f0c","922309fffb6940f8b26628c03734e47f","990b8a8f39144bddb5ea5a874ee2c902","9ed4fc85a1ab43f7bea3f0e35c0be790","e8083ddf94a1490a9044147bd0eedf6f","58d5c407ac1e4c1382b3511bb7a8f9a6","91399d2c0c3344f38ee66079e3384196","7403f69525494a73b81f0912ff4f5182","e895a0d15e2e49edad712f8707283734","9d7e739512d243eb96e38ad5ce1e17f7","1ff661e3c04449cea4a6995da9e8607b","e0406fb694ad4c9cb00761677af9fb78","407390252d6d48d7a8adfd6ba14e5170","5cbc92e76e6441d4945385add96b6ecb","834f52336c8a4febaca7a3edd464de3b","a798944d696a40cea70e219f856e295a","563121d17b2841a5ba73babd588cf093","0ac5fde0daaf497480737c1918c46434","cafe3c7287fd4180b3894ad1ec434551","c4bbdce4d6a74d7480d37f1aa45ec934","15a862b986a547d094323319ba635cd2","47336af7ec514672be5d1bda45206ed1","10be29a8bdf042019be93b1042df157d","85e68e35721a45038c4c9767b7bc781c","86b42d1755bc4f0e9989c7753799c69b","5b24f49376384c9dbe8cf87115471257","508e37618740480fac68d8f4d470ac2b","e6f22a2d77f84b5cb6a2d931e7e2ac4f","70f651e0e39344cab8a6e566ad316db5","e8080236bd7a41babfbe70acfd3f71be","f7927ccd7cbc48ec8db347795504d7f8","19e1132d04454b75ae25971499834e32","696f6632f3ef4e4db6998c466e2898a9","c96cae1a820e4d15848369d393079525","c09b88fcc9264cad9d34c757515f9c7c","edf8a73052964e1680f77b45533f6f85","a6edfec8058042b387aa00afc47556bd","320144d990b547cfa73b7c9e2fec661c","3b36ae7f945a41e1ba6c463ebac7809e","4484a043dd4b4c719eecac74475220bc","91eaaae50fad4de0a5f5af766e23bf28","ae70b8dccfd54b33a52ee23b6ef5e229","01c55a7cde3547b48647b457cdb99b29","ad34d240130840afaa609ffe960a1666","d462d2cdf3e44852bdd802eff06a18d7","f0b54579138c454a814a77612131f117","b4125f7f50924ce09e2ca4f478cad2b4","15004bdaeeb1403c8853b5ff3824d28f","05dd838e7de3446ba9e62c4acbc4e61b","b3f1b794e7f3468b9bd4a945b740e3f8","383903897c964f8ab4803fe212043c14","caa9037e9a9a4b5380576b35d5087aaa","208f1d298ad04059bada9f92078447cc","68b725926e7e4379a392d29e4e711665","a0c57aa9d7f74f2babd3c7ab7a9dc5b1","ca6e9e6c8e6643c5802ea44d7df8cd10","e135d2055a8c4963994e2a57c1131f3f","4c1f6395d3334b68bf2dd6de755dc26d","4b6e2c22b6f047459adb603ec6b48a9e","7f163726bf2b4a368198fdfe606c9c0b","e2ba10c42eb34d5ca49046a2e16f4c83","fa28b129a4c14c14bd8b7d8f188b5810","4ac43f0c7a744633ac39d207101c3a2d","e88b0af2c5d6488c83cd8c283da2ac67","0f06df6451dc490aba8763e53c8427c4","0dac594a532b4644b8bdecdc92fffdd3","16c1659881a44ac4a32fee8a1b9e48d4","accc5ba576244184a1c233fe681d635b","c76db3e31c484ababe57765371588c9a","05305e45b7044f80a790a575df1cce28","57980b04a02645cabfeabbff92f7b0ce","6cd9646b327b48ebbfe61e0472d25bca","f2c893dcaa124d51a94f5b6b03b5b3b2","b14cf7201c2546d28ba6ce70e62dc680","0599a0e33dd94f8eb3a4a4bb9030a364","f9a64db1546d4ec0a5076428f4355d83","7b71b21bfbf244b2822d294bc3dbc358","ddca01d4ed3744bca6288830d908aeb4","d8eee2c459534ae6a1f082f98405b387","af13d2eb8d904cd38dc4336ceacee882","204fad33f79e40afbc50fa1c3f8f7da2","e4ff4a26466b48c0987ddc8c8b134952","06df47becfa2411b8d9a4a0044f74764","fd6ba145b0ea4f8c8c8ffa9440d1942e","54f0b1bd311940c68f41c2d50c167540","53edcfa2fed4467ca36557f42b80fbad","9008eba744714ecbbf000b09456dc125","fd230be74e2046d49a7f1934a78fae31","d67627066bd54293a30870f5711cf92b","67f86e208cef46cf92e8f6762f22a022","ff635b8e4e4e4518a1fe305c9baad9d9","2af678e320b84b3f9764704d04842251","038e9f997ca04cc2bd1620a9f23e3d61"]},"executionInfo":{"status":"ok","timestamp":1667946035800,"user_tz":300,"elapsed":899135,"user":{"displayName":"Deep Learning (Deep Learning)","userId":"05582513555958405370"}},"outputId":"1b4e1df3-e9db-42a5-bb3c-bed7cc47d81e"},"outputs":[{"output_type":"stream","name":"stdout","text":["-----------------------------------\n","Epoch 1\n","-----------------------------------\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/227 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e3468ca6c468413d8348da01a3a6d6c0"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/8 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"add8b565459f4cfa9d85e40f74e3170c"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Training Loss: 5.5072. Validation Loss: 5.1946. \n","Training Perplexity: 246.4544. Validation Perplexity: 180.2892. \n","-----------------------------------\n","Epoch 2\n","-----------------------------------\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/227 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"58d5c407ac1e4c1382b3511bb7a8f9a6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/8 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"563121d17b2841a5ba73babd588cf093"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Training Loss: 5.2549. Validation Loss: 5.1946. \n","Training Perplexity: 191.5023. Validation Perplexity: 180.2892. \n","-----------------------------------\n","Epoch 3\n","-----------------------------------\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/227 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e6f22a2d77f84b5cb6a2d931e7e2ac4f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/8 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b36ae7f945a41e1ba6c463ebac7809e"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Training Loss: 5.2549. Validation Loss: 5.1946. \n","Training Perplexity: 191.5050. Validation Perplexity: 180.2892. \n","-----------------------------------\n","Epoch 4\n","-----------------------------------\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/227 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b3f1b794e7f3468b9bd4a945b740e3f8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/8 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e2ba10c42eb34d5ca49046a2e16f4c83"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Training Loss: 5.2549. Validation Loss: 5.1946. \n","Training Perplexity: 191.5006. Validation Perplexity: 180.2892. \n","-----------------------------------\n","Epoch 5\n","-----------------------------------\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/227 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6cd9646b327b48ebbfe61e0472d25bca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/8 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"06df47becfa2411b8d9a4a0044f74764"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Training Loss: 5.2550. Validation Loss: 5.1946. \n","Training Perplexity: 191.5145. Validation Perplexity: 180.2892. \n"]}],"source":["# Cell 18\n","# If training freezes it is due to memory error\n","for epoch_idx in range(EPOCHS):\n","    print(\"-----------------------------------\")\n","    print(\"Epoch %d\" % (epoch_idx+1))\n","    print(\"-----------------------------------\")\n","    \n","    train_loss, avg_train_loss = train(seq2seq_model, train_loader, optimizer, criterion)\n","    scheduler.step(train_loss)\n","\n","    val_loss, avg_val_loss = evaluate(seq2seq_model, valid_loader, criterion)\n","\n","    avg_train_loss = avg_train_loss.item()\n","    avg_val_loss = avg_val_loss.item()\n","    print(\"Training Loss: %.4f. Validation Loss: %.4f. \" % (avg_train_loss, avg_val_loss))\n","    print(\"Training Perplexity: %.4f. Validation Perplexity: %.4f. \" % (np.exp(avg_train_loss), np.exp(avg_val_loss)))"],"id":"OWFIwNJrKDWJ"},{"cell_type":"markdown","metadata":{"id":"X9VOyPUDQcUI"},"source":["### **2.1: Report Section: Seq2Seq Results [4 pts]**\n","Please edit this section to answer the following questions:\n","\n","1) Put your loss & perplexities from training here, both before and after hyperparameter tuning.\n","\n","2) Explain what you did here as well.\n"],"id":"X9VOyPUDQcUI"},{"cell_type":"markdown","metadata":{"id":"O5bYcPwGGVUP"},"source":["### Part 3: Train a Transformer\n","\n","We will be implementing a one-layer Transformer **encoder** which, similar to an RNN, can encode a sequence of inputs and produce a final output of possibility of tokens in target language. \n","\n","You can refer to the [original paper](https://arxiv.org/pdf/1706.03762.pdf) for more details."],"id":"O5bYcPwGGVUP"},{"cell_type":"markdown","metadata":{"id":"dJtx4rPa--t0"},"source":["#### The Corpus of Linguistic Acceptability (CoLA)\n","\n","The Corpus of Linguistic Acceptability ([CoLA](https://nyu-mll.github.io/CoLA/)) in its full form consists of 10657 sentences from 23 linguistics publications, expertly annotated for acceptability (grammaticality) by their original authors. Native English speakers consistently report a sharp contrast in acceptability between pairs of sentences. \n","Some examples include:\n","\n","`What did Betsy paint a picture of?` (Correct)\n","\n","`What was a picture of painted by Betsy?` (Incorrect)\n","\n","You can read more info about the dataset [here](https://arxiv.org/pdf/1805.12471.pdf). This is a binary classification task (predict 1 for correct grammar and 0 otherwise).\n","\n","We will be using this dataset as a sanity checker for the forward pass of the Transformer architecture discussed in class. The general intuitive notion is that we will _encode_ the sequence of tokens in the sentence, and then predict a binary output based on the final state that is the output of the model."],"id":"dJtx4rPa--t0"},{"cell_type":"markdown","metadata":{"id":"Mqq0J-Yvs35Z"},"source":["#### Load the preprocessed data\n","\n","We've appended a \"CLS\" token to the beginning of each sequence, which can be used to make predictions. The benefit of appending this token to the beginning of the sequence (rather than the end) is that we can extract it quite easily (we don't need to remove paddings and figure out the length of each individual sequence in the batch). We'll come back to this.\n","\n","We've additionally already constructed a vocabulary and converted all of the strings of tokens into integers which can be used for vocabulary lookup for you. Feel free to explore the data here."],"id":"Mqq0J-Yvs35Z"},{"cell_type":"code","execution_count":11,"metadata":{"id":"V19KfSYFsgyH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668118240745,"user_tz":300,"elapsed":1238,"user":{"displayName":"Deep Learning (Deep Learning)","userId":"05582513555958405370"}},"outputId":"edfd8698-c6a1-4c69-96e8-372fc2082e8d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Vocabulary Size: 1542\n","(7000, 43)\n","(1551, 43)\n","(7000,)\n","(1551,)\n"]}],"source":["# Cell 19\n","train_inxs = np.load('./data/train_inxs.npy')\n","val_inxs = np.load('./data/val_inxs.npy')\n","train_labels = np.load('./data/train_labels.npy')\n","val_labels = np.load('./data/val_labels.npy')\n","\n","# load dictionary\n","word_to_ix = {}\n","with open(\"./data/word_to_ix.csv\", \"r\") as f:\n","    reader = csv.reader(f)\n","    for line in reader:\n","        word_to_ix[line[0]] = line[1]\n","print(\"Vocabulary Size:\", len(word_to_ix))\n","        \n","print(train_inxs.shape) # 7000 training instances, of (maximum/padded) length 43 words.\n","print(val_inxs.shape) # 1551 validation instances, of (maximum/padded) length 43 words.\n","print(train_labels.shape)\n","print(val_labels.shape)\n","\n","d1 = torch.load('./data/d1.pt') \n","d2 = torch.load('./data/d2.pt')\n","d3 = torch.load('./data/d3.pt')\n","d4 = torch.load('./data/d4.pt')"],"id":"V19KfSYFsgyH"},{"cell_type":"markdown","metadata":{"id":"Hi58_oYd_MpZ"},"source":["Instead of using numpy for this model, we will be using Pytorch to implement the forward pass. You will not need to implement the backward pass for the various layers in this assigment.\n","\n","The file `models/Transformer.py` contains the model class and methods for each layer. This is where you will write your implementations."],"id":"Hi58_oYd_MpZ"},{"cell_type":"markdown","metadata":{"id":"JkXVnxXYs6Pc"},"source":["#### 3.1 Embeddings\n","\n","We will format our input embeddings similarly to how they are constructed in [BERT (source of figure)](https://arxiv.org/pdf/1810.04805.pdf). Recall from lecture that unlike a RNN, a Transformer does not include any positional information about the order in which the words in the sentence occur. Because of this, we need to append a positional encoding token at each position. (We will ignore the segment embeddings and [SEP] token here, since we are only encoding one sentence at a time). We have already appended the [CLS] token for you in the previous step.\n","\n","Your first task is to implement the embedding lookup, including the addition of positional encodings. Open the file `transformer.py` and complete all code parts."],"id":"JkXVnxXYs6Pc"},{"cell_type":"code","execution_count":70,"metadata":{"id":"XyYcE5oJsgrA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668122968043,"user_tz":300,"elapsed":629,"user":{"displayName":"Deep Learning (Deep Learning)","userId":"05582513555958405370"}},"outputId":"50fecc79-7e48-41a9-eaa3-b996628fee19"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([2, 43])\n","torch.Size([2, 43, 128])\n","torch.Size([2, 43, 128])\n","Difference: 0.0017998493276536465\n"]}],"source":["# Cell 20\n","from models.Transformer import TransformerTranslator\n","\n","inputs = train_inxs[0:2]\n","inputs = torch.LongTensor(inputs)\n","\n","model = TransformerTranslator(input_size=len(word_to_ix), output_size=2, device='cpu', hidden_dim=128, num_heads=2, dim_feedforward=2048, dim_k=96, dim_v=96, dim_q=96, max_length=train_inxs.shape[1])\n","\n","embeds = model.embed(inputs)\n","print(inputs.size())\n","print(d1.size())\n","print(embeds.size())\n","try:\n","    print(\"Difference:\", torch.sum(torch.pairwise_distance(embeds, d1)).item()) # should be very small (<0.01)\n","except:\n","    print(\"NOT IMPLEMENTED\")"],"id":"XyYcE5oJsgrA"},{"cell_type":"markdown","metadata":{"id":"08kgK0Y1s-rN"},"source":["#### 3.2 Multi-head Self-Attention\n","\n","We want to have multiple self-attention operations, computed in parallel. Each of these is called a *head*. We concatenate the heads and multiply them with the matrix `attention_head_projection` to produce the output of this layer.\n","\n","After every multi-head self-attention and feedforward layer, there is a residual connection + layer normalization. \n","\n","Open the file `models/transformer.py` and implement the `multihead_attention` function. \n","We have already initialized all of the layers you will need in the constructor."],"id":"08kgK0Y1s-rN"},{"cell_type":"code","execution_count":71,"metadata":{"id":"L3pvunOdsgkZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668122969581,"user_tz":300,"elapsed":152,"user":{"displayName":"Deep Learning (Deep Learning)","userId":"05582513555958405370"}},"outputId":"f9188f8c-9508-4b06-f82a-22f738bf9c59"},"outputs":[{"output_type":"stream","name":"stdout","text":["Difference: 0.0017089800676330924\n"]}],"source":["# Cell 21\n","hidden_states = model.multi_head_attention(embeds)\n","\n","try:\n","    print(\"Difference:\", torch.sum(torch.pairwise_distance(hidden_states, d2)).item()) # should be very small (<0.01)\n","except:\n","    print(\"NOT IMPLEMENTED\")"],"id":"L3pvunOdsgkZ"},{"cell_type":"markdown","metadata":{"id":"d69dj0bctGjx"},"source":["#### 3.3 Element-Wise Feed-forward Layer\n","\n","Open the file `models/transformer.py` and complete codes: Include layer norm and addition as per transformer diagram."],"id":"d69dj0bctGjx"},{"cell_type":"code","execution_count":72,"metadata":{"id":"LFp9uojKsgd2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668122970899,"user_tz":300,"elapsed":299,"user":{"displayName":"Deep Learning (Deep Learning)","userId":"05582513555958405370"}},"outputId":"f27e7f44-28f1-4ae6-a9df-e795af85e84e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Difference: 0.001713332487270236\n"]}],"source":["# Cell 22\n","outputs = model.feedforward_layer(hidden_states)\n","\n","try:\n","    print(\"Difference:\", torch.sum(torch.pairwise_distance(outputs, d3)).item()) # should be very small (<0.01)\n","except:\n","    print(\"NOT IMPLEMENTED\")"],"id":"LFp9uojKsgd2"},{"cell_type":"markdown","metadata":{"id":"UfpyrCnttKGM"},"source":["#### 3.4 Final Layer\n","\n","Open the file `models/transformer.py` and complete codes, to produce logits for all tokens in target language.\n","\n","NOTE: Since the transformer is for translation and not classification, the size of the `scores` tensor will be \\[2, 43, 2\\]. This is okay for our purposes."],"id":"UfpyrCnttKGM"},{"cell_type":"code","execution_count":73,"metadata":{"id":"u2BUtXw-sgN0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668122971913,"user_tz":300,"elapsed":117,"user":{"displayName":"Deep Learning (Deep Learning)","userId":"05582513555958405370"}},"outputId":"16f3c938-2d1e-476d-c3a0-082cf1ce6874"},"outputs":[{"output_type":"stream","name":"stdout","text":["Difference: 2.6047251594718546e-05\n"]}],"source":["# Cell 23\n","scores = model.final_layer(outputs)\n","\n","try:\n","    print(\"Difference:\", torch.sum(torch.pairwise_distance(scores, d4)).item()) # should be very small (<1e-5)\n","except:\n","    print(\"NOT IMPLEMENTED\")"],"id":"u2BUtXw-sgN0"},{"cell_type":"markdown","metadata":{"id":"3bHJAVD1tMwC"},"source":["#### 3.5 Forward Pass\n","\n","Open the file `models/Transformer.py` and complete the method `forward`, by putting together all of the methods you have developed in the right order to perform a full forward pass."],"id":"3bHJAVD1tMwC"},{"cell_type":"code","execution_count":74,"metadata":{"id":"RHlf0Y2Wsw6A","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668123045682,"user_tz":300,"elapsed":702,"user":{"displayName":"Deep Learning (Deep Learning)","userId":"05582513555958405370"}},"outputId":"6ddeaa01-47be-421c-d9ac-96589329993f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Difference: 2.6229748982586898e-05\n"]}],"source":["# Cell 24\n","inputs = train_inxs[0:2]\n","inputs = torch.LongTensor(inputs)\n","\n","outputs = model.forward(inputs)\n","\n","try:\n","    print(\"Difference:\", torch.sum(torch.pairwise_distance(outputs, scores)).item()) # should be very small (<1e-5)\n","except:\n","    print(\"NOT IMPLEMENTED\")"],"id":"RHlf0Y2Wsw6A"},{"cell_type":"markdown","metadata":{"id":"9PCAPbynAAij"},"source":["Great! We've just implemented a Transformer forward pass for translation. One of the big perks of using PyTorch is that with a simple training loop, we can rely on automatic differentation ([autograd](https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html)) to do the work of the backward pass for us. This is not required for this assignment, but you can explore this on your own."],"id":"9PCAPbynAAij"},{"cell_type":"markdown","metadata":{"id":"NTefenDDtP_E"},"source":["#### 3.6 Training and Hyperparameter Tuning\n","\n","Now you can start training the Transformer translator on the original sequence to sequence task. We provided you with some training code and you can simply run them to see how your translator works. If you implemented everything correctly, you should see some meaningful translation in the output. Compare the results from the Seq2Seq model, which one is better? You can modify the hyperparameters to improve the results. You can also tune the BATCH_SIZE in section Preprocess Data."],"id":"NTefenDDtP_E"},{"cell_type":"code","execution_count":null,"metadata":{"id":"y2mggFZort4e"},"outputs":[],"source":["# Cell 25\n","from models.Transformer import TransformerTranslator\n","\n","# Hyperparameters\n","learning_rate = 1e-1\n","EPOCHS = 5\n","\n","# Model\n","model = TransformerTranslator(input_size, output_size, device, max_length = MAX_LEN).to(device)\n","\n","# optimizer = optim.Adam(model.parameters(), lr = learning_rate)\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)\n","criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)"],"id":"y2mggFZort4e"},{"cell_type":"code","execution_count":null,"metadata":{"id":"777QG6bsr2on"},"outputs":[],"source":["for epoch_idx in range(EPOCHS):\n","    print(\"-----------------------------------\")\n","    print(\"Epoch %d\" % (epoch_idx+1))\n","    print(\"-----------------------------------\")\n","    \n","    train_loss, avg_train_loss = train(model, train_loader, optimizer, criterion)\n","    scheduler.step(train_loss)\n","\n","    val_loss, avg_val_loss = evaluate(model, valid_loader, criterion)\n","\n","    avg_train_loss = avg_train_loss.item()\n","    avg_val_loss = avg_val_loss.item()\n","    print(\"Training Loss: %.4f. Validation Loss: %.4f. \" % (avg_train_loss, avg_val_loss))\n","    print(\"Training Perplexity: %.4f. Validation Perplexity: %.4f. \" % (np.exp(avg_train_loss), np.exp(avg_val_loss)))"],"id":"777QG6bsr2on"},{"cell_type":"markdown","metadata":{"id":"tf6zD6iNR7ph"},"source":["### **Report Section: Transformer Results [5 pts]**\n","Please edit this section to answer the following questions:\n","\n","1) Put your loss & perplexities from training here, both before and after hyperparameter tuning.\n","\n","2) Explain what you did here as well."],"id":"tf6zD6iNR7ph"},{"cell_type":"markdown","metadata":{"id":"_5mJSk5CFY2C"},"source":["**Translations**\n","\n","Run the code below to see some of your translations. Modify to your liking."],"id":"_5mJSk5CFY2C"},{"cell_type":"code","execution_count":null,"metadata":{"id":"11QRpvmvsCUZ"},"outputs":[],"source":["# Cell 26\n","def translate(model, dataloader):\n","    model.eval()\n","    with torch.no_grad():\n","        # Get the progress bar \n","        #progress_bar = tqdm(dataloader, asci = True)\n","        for batch_idx, data in enumerate(dataloader):\n","            source = data.src.transpose(1,0)\n","            target = data.trg.transpose(1,0)\n","\n","            translation = model(source)\n","            return target, translation"],"id":"11QRpvmvsCUZ"},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z8giy9hnsTXc"},"outputs":[],"source":["# Cell 27\n","# Select Transformer or Seq2Seq model\n","# model = trans_model\n","model = seq2seq_model"],"id":"Z8giy9hnsTXc"},{"cell_type":"code","execution_count":null,"metadata":{"id":"G-IzLmCSsVUY"},"outputs":[],"source":["# Cell 28\n","#Set model equal to trans_model or seq2seq_model\n","target, translation = translate(model, valid_loader)"],"id":"G-IzLmCSsVUY"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":639,"status":"ok","timestamp":1666590744690,"user":{"displayName":"Adi Singh","userId":"16190443974430821767"},"user_tz":240},"id":"HIM-jp0AsXQD","outputId":"7d2b1112-d735-4c76-ffb1-346dc1f1e446"},"outputs":[{"name":"stdout","output_type":"stream","text":["[['<sos>' 'a' 'man' ... '<pad>' '<pad>' '<pad>']\n"," ['<sos>' 'a' 'man' ... '<pad>' '<pad>' '<pad>']\n"," ['<sos>' 'a' 'man' ... '<pad>' '<pad>' '<pad>']\n"," ...\n"," ['<sos>' 'boy' 'doing' ... '<pad>' '<pad>' '<pad>']\n"," ['<sos>' 'kids' 'are' ... '<pad>' '<pad>' '<pad>']\n"," ['<sos>' 'a' 'man' ... '<pad>' '<pad>' '<pad>']]\n"]}],"source":["# Cell 29\n","raw = np.array([list(map(lambda x: TRG.vocab.itos[x], target[i])) for i in range(target.shape[0])])\n","print(raw)"],"id":"HIM-jp0AsXQD"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1666590746785,"user":{"displayName":"Adi Singh","userId":"16190443974430821767"},"user_tz":240},"id":"V15jSe37tbzQ","outputId":"97007743-880d-4930-9f66-d15cabd8c2d1"},"outputs":[{"name":"stdout","output_type":"stream","text":["[['<unk>' 'a' 'man' ... '<eos>' '<eos>' '<eos>']\n"," ['<unk>' 'a' 'man' ... '<eos>' '<eos>' '<eos>']\n"," ['<unk>' 'a' 'man' ... '<eos>' '<eos>' '<eos>']\n"," ...\n"," ['<unk>' 'a' 'man' ... '<eos>' '<eos>' '<eos>']\n"," ['<unk>' 'a' 'man' ... '<eos>' '<eos>' '<eos>']\n"," ['<unk>' 'a' 'man' ... '<eos>' '<eos>' '<eos>']]\n"]}],"source":["# Cell 30\n","token_trans = np.argmax(translation.cpu().numpy(), axis = 2)\n","translated = np.array([list(map(lambda x: TRG.vocab.itos[x], token_trans[i])) for i in range(token_trans.shape[0])])\n","print(translated)"],"id":"V15jSe37tbzQ"},{"cell_type":"markdown","metadata":{"id":"DJq4sV4Hz0dx"},"source":["### Zip submission and submit to Gradescope"],"id":"DJq4sV4Hz0dx"},{"cell_type":"markdown","metadata":{"id":"4883a991"},"source":["If on Linux or Mac, run the following cell:"],"id":"4883a991"},{"cell_type":"code","execution_count":null,"metadata":{"id":"vBW39ZiCjLmH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"error","timestamp":1667946399645,"user_tz":300,"elapsed":747,"user":{"displayName":"Deep Learning (Deep Learning)","userId":"05582513555958405370"}},"outputId":"b8a31689-cc4d-4f28-cc74-c8f00b977833"},"outputs":[{"output_type":"stream","name":"stderr","text":["UsageError: Line magic function `%zip` not found.\n"]}],"source":["!cd /content/drive/MyDrive/hw4_student_version\n","%rm -rf assignment4_submission.zip\n","%zip -r assignment4_submission.zip models/ Machine_Translation.ipynb"],"id":"vBW39ZiCjLmH"},{"cell_type":"markdown","metadata":{"id":"2d66d84c"},"source":["If on Windows, run the following cell:"],"id":"2d66d84c"},{"cell_type":"code","execution_count":null,"metadata":{"id":"10c1e638","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1667946244807,"user_tz":300,"elapsed":471,"user":{"displayName":"Deep Learning (Deep Learning)","userId":"05582513555958405370"}},"outputId":"aee47fca-8a3a-49f2-db7c-8ec6766ee0f0"},"outputs":[{"output_type":"stream","name":"stdout","text":["/bin/bash: collect_submission.bat: command not found\n"]}],"source":["!cd /content/drive/MyDrive/hw4_student_version/\n","!collect_submission.bat"],"id":"10c1e638"},{"cell_type":"code","source":["!sh collect_submission.sh"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MHqSKwyGV9gS","executionInfo":{"status":"ok","timestamp":1667946452875,"user_tz":300,"elapsed":3272,"user":{"displayName":"Deep Learning (Deep Learning)","userId":"05582513555958405370"}},"outputId":"1512d6a3-9f61-43fb-9cb1-feec550b5d81"},"id":"MHqSKwyGV9gS","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["  adding: models/ (stored 0%)\n","  adding: models/seq2seq/ (stored 0%)\n","  adding: models/seq2seq/__pycache__/ (stored 0%)\n","  adding: models/seq2seq/__pycache__/Decoder.cpython-37.pyc (deflated 43%)\n","  adding: models/seq2seq/__pycache__/Encoder.cpython-37.pyc (deflated 44%)\n","  adding: models/seq2seq/__pycache__/Seq2Seq.cpython-37.pyc (deflated 40%)\n","  adding: models/seq2seq/Decoder.py (deflated 74%)\n","  adding: models/seq2seq/Encoder.py (deflated 74%)\n","  adding: models/seq2seq/Seq2Seq.py (deflated 72%)\n","  adding: models/naive/ (stored 0%)\n","  adding: models/naive/__pycache__/ (stored 0%)\n","  adding: models/naive/__pycache__/RNN.cpython-37.pyc (deflated 52%)\n","  adding: models/naive/__pycache__/LSTM.cpython-37.pyc (deflated 47%)\n","  adding: models/naive/RNN.py (deflated 72%)\n","  adding: models/naive/LSTM.py (deflated 74%)\n","  adding: models/__pycache__/ (stored 0%)\n","  adding: models/__pycache__/Transformer.cpython-37.pyc (deflated 58%)\n","  adding: models/Transformer.py (deflated 81%)\n","  adding: Machine_Translation.ipynb (deflated 86%)\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"YcgLsjX5Wwnq"},"id":"YcgLsjX5Wwnq","execution_count":null,"outputs":[]}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.8.13 ('dl_hw4_v2')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.13"},"vscode":{"interpreter":{"hash":"2bc44c6deab8467600c4ac5d8dc0b74ce1e3f255b556a694324362962bd0737f"}},"widgets":{"application/vnd.jupyter.widget-state+json":{"e3468ca6c468413d8348da01a3a6d6c0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8ce1395edf434a37b3c6496b2b1ec638","IPY_MODEL_279a33ace54e4eeca3f944e56efbae41","IPY_MODEL_3abd786ef55547cbb47ded55d1679972"],"layout":"IPY_MODEL_d52c36ee63d44e5fafd2326a571a0b0d"}},"8ce1395edf434a37b3c6496b2b1ec638":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9f9c06d838ce4a1d973c4c6faf863ecf","placeholder":"​","style":"IPY_MODEL_a9d9c083e54d4ea697c4f00e6238dbaa","value":"Batch: 227, Loss: 5.4269: 100%"}},"279a33ace54e4eeca3f944e56efbae41":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d6cd62dc037f4a9aa3240b7432865845","max":227,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5e3d3a287edc49a588ad51a0513c14f1","value":227}},"3abd786ef55547cbb47ded55d1679972":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cf7a78180db44605be2bb0feaeee0a7d","placeholder":"​","style":"IPY_MODEL_703695b62db5469eb7c64dc4d7dc4419","value":" 227/227 [02:55&lt;00:00,  1.38it/s]"}},"d52c36ee63d44e5fafd2326a571a0b0d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9f9c06d838ce4a1d973c4c6faf863ecf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a9d9c083e54d4ea697c4f00e6238dbaa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d6cd62dc037f4a9aa3240b7432865845":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5e3d3a287edc49a588ad51a0513c14f1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cf7a78180db44605be2bb0feaeee0a7d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"703695b62db5469eb7c64dc4d7dc4419":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"add8b565459f4cfa9d85e40f74e3170c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9e21e636599b42dcbf4512dc94e8ed83","IPY_MODEL_e83267fc131b4537880e261443bcc962","IPY_MODEL_0a54c0c4483b47498b008533819bcec5"],"layout":"IPY_MODEL_ddf9ba0fa84e425ba4ce75ddaeedf3d5"}},"9e21e636599b42dcbf4512dc94e8ed83":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_03eedd1394504ef9b6bfb075e18d3fc0","placeholder":"​","style":"IPY_MODEL_c2be8a89d4a34cdbb1e2658506848f0c","value":"Batch: 8, Loss: 5.5331: 100%"}},"e83267fc131b4537880e261443bcc962":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_922309fffb6940f8b26628c03734e47f","max":8,"min":0,"orientation":"horizontal","style":"IPY_MODEL_990b8a8f39144bddb5ea5a874ee2c902","value":8}},"0a54c0c4483b47498b008533819bcec5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9ed4fc85a1ab43f7bea3f0e35c0be790","placeholder":"​","style":"IPY_MODEL_e8083ddf94a1490a9044147bd0eedf6f","value":" 8/8 [00:03&lt;00:00,  2.53it/s]"}},"ddf9ba0fa84e425ba4ce75ddaeedf3d5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"03eedd1394504ef9b6bfb075e18d3fc0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c2be8a89d4a34cdbb1e2658506848f0c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"922309fffb6940f8b26628c03734e47f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"990b8a8f39144bddb5ea5a874ee2c902":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9ed4fc85a1ab43f7bea3f0e35c0be790":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e8083ddf94a1490a9044147bd0eedf6f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"58d5c407ac1e4c1382b3511bb7a8f9a6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_91399d2c0c3344f38ee66079e3384196","IPY_MODEL_7403f69525494a73b81f0912ff4f5182","IPY_MODEL_e895a0d15e2e49edad712f8707283734"],"layout":"IPY_MODEL_9d7e739512d243eb96e38ad5ce1e17f7"}},"91399d2c0c3344f38ee66079e3384196":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1ff661e3c04449cea4a6995da9e8607b","placeholder":"​","style":"IPY_MODEL_e0406fb694ad4c9cb00761677af9fb78","value":"Batch: 227, Loss: 5.2983: 100%"}},"7403f69525494a73b81f0912ff4f5182":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_407390252d6d48d7a8adfd6ba14e5170","max":227,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5cbc92e76e6441d4945385add96b6ecb","value":227}},"e895a0d15e2e49edad712f8707283734":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_834f52336c8a4febaca7a3edd464de3b","placeholder":"​","style":"IPY_MODEL_a798944d696a40cea70e219f856e295a","value":" 227/227 [02:55&lt;00:00,  1.33it/s]"}},"9d7e739512d243eb96e38ad5ce1e17f7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1ff661e3c04449cea4a6995da9e8607b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e0406fb694ad4c9cb00761677af9fb78":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"407390252d6d48d7a8adfd6ba14e5170":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5cbc92e76e6441d4945385add96b6ecb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"834f52336c8a4febaca7a3edd464de3b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a798944d696a40cea70e219f856e295a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"563121d17b2841a5ba73babd588cf093":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0ac5fde0daaf497480737c1918c46434","IPY_MODEL_cafe3c7287fd4180b3894ad1ec434551","IPY_MODEL_c4bbdce4d6a74d7480d37f1aa45ec934"],"layout":"IPY_MODEL_15a862b986a547d094323319ba635cd2"}},"0ac5fde0daaf497480737c1918c46434":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_47336af7ec514672be5d1bda45206ed1","placeholder":"​","style":"IPY_MODEL_10be29a8bdf042019be93b1042df157d","value":"Batch: 8, Loss: 5.5331: 100%"}},"cafe3c7287fd4180b3894ad1ec434551":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_85e68e35721a45038c4c9767b7bc781c","max":8,"min":0,"orientation":"horizontal","style":"IPY_MODEL_86b42d1755bc4f0e9989c7753799c69b","value":8}},"c4bbdce4d6a74d7480d37f1aa45ec934":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5b24f49376384c9dbe8cf87115471257","placeholder":"​","style":"IPY_MODEL_508e37618740480fac68d8f4d470ac2b","value":" 8/8 [00:03&lt;00:00,  2.46it/s]"}},"15a862b986a547d094323319ba635cd2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"47336af7ec514672be5d1bda45206ed1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"10be29a8bdf042019be93b1042df157d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"85e68e35721a45038c4c9767b7bc781c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"86b42d1755bc4f0e9989c7753799c69b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5b24f49376384c9dbe8cf87115471257":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"508e37618740480fac68d8f4d470ac2b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e6f22a2d77f84b5cb6a2d931e7e2ac4f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_70f651e0e39344cab8a6e566ad316db5","IPY_MODEL_e8080236bd7a41babfbe70acfd3f71be","IPY_MODEL_f7927ccd7cbc48ec8db347795504d7f8"],"layout":"IPY_MODEL_19e1132d04454b75ae25971499834e32"}},"70f651e0e39344cab8a6e566ad316db5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_696f6632f3ef4e4db6998c466e2898a9","placeholder":"​","style":"IPY_MODEL_c96cae1a820e4d15848369d393079525","value":"Batch: 227, Loss: 5.2122: 100%"}},"e8080236bd7a41babfbe70acfd3f71be":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c09b88fcc9264cad9d34c757515f9c7c","max":227,"min":0,"orientation":"horizontal","style":"IPY_MODEL_edf8a73052964e1680f77b45533f6f85","value":227}},"f7927ccd7cbc48ec8db347795504d7f8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a6edfec8058042b387aa00afc47556bd","placeholder":"​","style":"IPY_MODEL_320144d990b547cfa73b7c9e2fec661c","value":" 227/227 [02:56&lt;00:00,  1.31it/s]"}},"19e1132d04454b75ae25971499834e32":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"696f6632f3ef4e4db6998c466e2898a9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c96cae1a820e4d15848369d393079525":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c09b88fcc9264cad9d34c757515f9c7c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"edf8a73052964e1680f77b45533f6f85":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a6edfec8058042b387aa00afc47556bd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"320144d990b547cfa73b7c9e2fec661c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3b36ae7f945a41e1ba6c463ebac7809e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4484a043dd4b4c719eecac74475220bc","IPY_MODEL_91eaaae50fad4de0a5f5af766e23bf28","IPY_MODEL_ae70b8dccfd54b33a52ee23b6ef5e229"],"layout":"IPY_MODEL_01c55a7cde3547b48647b457cdb99b29"}},"4484a043dd4b4c719eecac74475220bc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ad34d240130840afaa609ffe960a1666","placeholder":"​","style":"IPY_MODEL_d462d2cdf3e44852bdd802eff06a18d7","value":"Batch: 8, Loss: 5.5331: 100%"}},"91eaaae50fad4de0a5f5af766e23bf28":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f0b54579138c454a814a77612131f117","max":8,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b4125f7f50924ce09e2ca4f478cad2b4","value":8}},"ae70b8dccfd54b33a52ee23b6ef5e229":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_15004bdaeeb1403c8853b5ff3824d28f","placeholder":"​","style":"IPY_MODEL_05dd838e7de3446ba9e62c4acbc4e61b","value":" 8/8 [00:03&lt;00:00,  2.45it/s]"}},"01c55a7cde3547b48647b457cdb99b29":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ad34d240130840afaa609ffe960a1666":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d462d2cdf3e44852bdd802eff06a18d7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f0b54579138c454a814a77612131f117":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b4125f7f50924ce09e2ca4f478cad2b4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"15004bdaeeb1403c8853b5ff3824d28f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"05dd838e7de3446ba9e62c4acbc4e61b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b3f1b794e7f3468b9bd4a945b740e3f8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_383903897c964f8ab4803fe212043c14","IPY_MODEL_caa9037e9a9a4b5380576b35d5087aaa","IPY_MODEL_208f1d298ad04059bada9f92078447cc"],"layout":"IPY_MODEL_68b725926e7e4379a392d29e4e711665"}},"383903897c964f8ab4803fe212043c14":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a0c57aa9d7f74f2babd3c7ab7a9dc5b1","placeholder":"​","style":"IPY_MODEL_ca6e9e6c8e6643c5802ea44d7df8cd10","value":"Batch: 227, Loss: 5.2998: 100%"}},"caa9037e9a9a4b5380576b35d5087aaa":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e135d2055a8c4963994e2a57c1131f3f","max":227,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4c1f6395d3334b68bf2dd6de755dc26d","value":227}},"208f1d298ad04059bada9f92078447cc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4b6e2c22b6f047459adb603ec6b48a9e","placeholder":"​","style":"IPY_MODEL_7f163726bf2b4a368198fdfe606c9c0b","value":" 227/227 [02:57&lt;00:00,  1.30it/s]"}},"68b725926e7e4379a392d29e4e711665":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a0c57aa9d7f74f2babd3c7ab7a9dc5b1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ca6e9e6c8e6643c5802ea44d7df8cd10":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e135d2055a8c4963994e2a57c1131f3f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4c1f6395d3334b68bf2dd6de755dc26d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4b6e2c22b6f047459adb603ec6b48a9e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7f163726bf2b4a368198fdfe606c9c0b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e2ba10c42eb34d5ca49046a2e16f4c83":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fa28b129a4c14c14bd8b7d8f188b5810","IPY_MODEL_4ac43f0c7a744633ac39d207101c3a2d","IPY_MODEL_e88b0af2c5d6488c83cd8c283da2ac67"],"layout":"IPY_MODEL_0f06df6451dc490aba8763e53c8427c4"}},"fa28b129a4c14c14bd8b7d8f188b5810":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0dac594a532b4644b8bdecdc92fffdd3","placeholder":"​","style":"IPY_MODEL_16c1659881a44ac4a32fee8a1b9e48d4","value":"Batch: 8, Loss: 5.5331: 100%"}},"4ac43f0c7a744633ac39d207101c3a2d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_accc5ba576244184a1c233fe681d635b","max":8,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c76db3e31c484ababe57765371588c9a","value":8}},"e88b0af2c5d6488c83cd8c283da2ac67":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_05305e45b7044f80a790a575df1cce28","placeholder":"​","style":"IPY_MODEL_57980b04a02645cabfeabbff92f7b0ce","value":" 8/8 [00:03&lt;00:00,  2.43it/s]"}},"0f06df6451dc490aba8763e53c8427c4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0dac594a532b4644b8bdecdc92fffdd3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"16c1659881a44ac4a32fee8a1b9e48d4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"accc5ba576244184a1c233fe681d635b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c76db3e31c484ababe57765371588c9a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"05305e45b7044f80a790a575df1cce28":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"57980b04a02645cabfeabbff92f7b0ce":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6cd9646b327b48ebbfe61e0472d25bca":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f2c893dcaa124d51a94f5b6b03b5b3b2","IPY_MODEL_b14cf7201c2546d28ba6ce70e62dc680","IPY_MODEL_0599a0e33dd94f8eb3a4a4bb9030a364"],"layout":"IPY_MODEL_f9a64db1546d4ec0a5076428f4355d83"}},"f2c893dcaa124d51a94f5b6b03b5b3b2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7b71b21bfbf244b2822d294bc3dbc358","placeholder":"​","style":"IPY_MODEL_ddca01d4ed3744bca6288830d908aeb4","value":"Batch: 227, Loss: 5.2501: 100%"}},"b14cf7201c2546d28ba6ce70e62dc680":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d8eee2c459534ae6a1f082f98405b387","max":227,"min":0,"orientation":"horizontal","style":"IPY_MODEL_af13d2eb8d904cd38dc4336ceacee882","value":227}},"0599a0e33dd94f8eb3a4a4bb9030a364":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_204fad33f79e40afbc50fa1c3f8f7da2","placeholder":"​","style":"IPY_MODEL_e4ff4a26466b48c0987ddc8c8b134952","value":" 227/227 [02:56&lt;00:00,  1.32it/s]"}},"f9a64db1546d4ec0a5076428f4355d83":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7b71b21bfbf244b2822d294bc3dbc358":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ddca01d4ed3744bca6288830d908aeb4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d8eee2c459534ae6a1f082f98405b387":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"af13d2eb8d904cd38dc4336ceacee882":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"204fad33f79e40afbc50fa1c3f8f7da2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e4ff4a26466b48c0987ddc8c8b134952":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"06df47becfa2411b8d9a4a0044f74764":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fd6ba145b0ea4f8c8c8ffa9440d1942e","IPY_MODEL_54f0b1bd311940c68f41c2d50c167540","IPY_MODEL_53edcfa2fed4467ca36557f42b80fbad"],"layout":"IPY_MODEL_9008eba744714ecbbf000b09456dc125"}},"fd6ba145b0ea4f8c8c8ffa9440d1942e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fd230be74e2046d49a7f1934a78fae31","placeholder":"​","style":"IPY_MODEL_d67627066bd54293a30870f5711cf92b","value":"Batch: 8, Loss: 5.5331: 100%"}},"54f0b1bd311940c68f41c2d50c167540":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_67f86e208cef46cf92e8f6762f22a022","max":8,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ff635b8e4e4e4518a1fe305c9baad9d9","value":8}},"53edcfa2fed4467ca36557f42b80fbad":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2af678e320b84b3f9764704d04842251","placeholder":"​","style":"IPY_MODEL_038e9f997ca04cc2bd1620a9f23e3d61","value":" 8/8 [00:03&lt;00:00,  2.49it/s]"}},"9008eba744714ecbbf000b09456dc125":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fd230be74e2046d49a7f1934a78fae31":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d67627066bd54293a30870f5711cf92b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"67f86e208cef46cf92e8f6762f22a022":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ff635b8e4e4e4518a1fe305c9baad9d9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2af678e320b84b3f9764704d04842251":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"038e9f997ca04cc2bd1620a9f23e3d61":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}